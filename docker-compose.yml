name: devops-ai

services:
  db:
    image: postgres:16
    container_name: devops-ai-db
    env_file: .env
    volumes:
      - dbdata:/var/lib/postgresql/data
      - ./docker/db/init:/docker-entrypoint-initdb.d:ro
    ports:
      - "${POSTGRES_PORT}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 3s
      retries: 20
    restart: unless-stopped
    networks:
      - devops-ai-net

  ollama:
    image: ollama/ollama:latest
    container_name: devops-ai-ollama
    env_file: .env
    volumes:
      - ollama:/root/.ollama
    expose:
      - "11434"
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 5s
      timeout: 3s
      retries: 40
    restart: unless-stopped
    networks:
      devops-ai-net:
        aliases:
          - ollama
          - devops-ai-ollama

  chroma:
    image: chromadb/chroma:latest
    container_name: devops-ai-chroma
    env_file: .env
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8001
      - ALLOW_RESET=TRUE
    volumes:
      - chroma_data:/chroma/chroma
    ports:
      - "${CHROMA_PORT:-8001}:8001"
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8001/api/v1/heartbeat').raise_for_status()"]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 30s
    restart: unless-stopped
    networks:
      devops-ai-net:
        aliases:
          - chroma
          - devops-ai-chroma

  api:
    build:
      context: .
      dockerfile: src/app/api/Dockerfile
    container_name: devops-ai-api
    env_file: .env
    environment:
      PYTHONWARNINGS: ignore::SyntaxWarning
      AZURE_LOG_LEVEL: warning
      JWT_SECRET_KEY: ${JWT_SECRET_KEY}
      APPLICATIONINSIGHTS_CONNECTION_STRING: ${APPLICATIONINSIGHTS_CONNECTION_STRING}
      LLM_PROVIDER: ${LLM_PROVIDER:-openai}
      LLM__OLLAMA_BASE_URL: http://ollama:11434
      LLM__OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      LLM__OPENAI_API_BASE: ${OPENAI_API_BASE:-https://api.openai.com/v1}
      VECTOR_PROVIDER: ${VECTOR_PROVIDER:-chroma}
      VECTOR_HOST: ${VECTOR_HOST:-chroma}
      VECTOR_PORT: ${VECTOR_PORT:-8001}
      VECTOR_EMBEDDING_MODEL: ${VECTOR_EMBEDDING_MODEL:-text-embedding-3-small}
      VECTOR_DIMENSION: ${VECTOR_DIMENSION:-1536}
      VECTOR_AUTO_INDEX: ${VECTOR_AUTO_INDEX:-true}
      VECTOR_CACHE_TTL_HOURS: ${VECTOR_CACHE_TTL_HOURS:-24}
    ports:
      - "${API_PORT}:${API_PORT}"
    depends_on:
      db:
        condition: service_healthy
      ollama:
        condition: service_healthy
      chroma:
        condition: service_healthy
    command: >
      sh -c "uvicorn app.api.main:app --host ${API_HOST} --port ${API_PORT} --workers 1"
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:${API_PORT}${API_PREFIX}/health || exit 1"]
    restart: unless-stopped
    networks:
      - devops-ai-net

  mcp:
    build:
      context: .
      dockerfile: src/app/api/Dockerfile
    container_name: devops-ai-mcp
    env_file: .env
    environment:
      VECTOR_PROVIDER: ${VECTOR_PROVIDER:-chroma}
      VECTOR_HOST: ${VECTOR_HOST:-chroma}
      VECTOR_PORT: ${VECTOR_PORT:-8001}
      VECTOR_EMBEDDING_MODEL: ${VECTOR_EMBEDDING_MODEL:-text-embedding-3-small}
      VECTOR_DIMENSION: ${VECTOR_DIMENSION:-1536}
      VECTOR_AUTO_INDEX: ${VECTOR_AUTO_INDEX:-true}
      VECTOR_CACHE_TTL_HOURS: ${VECTOR_CACHE_TTL_HOURS:-24}
    depends_on:
      db:
        condition: service_healthy
      chroma:
        condition: service_healthy
    command: >
      sh -c "python -m app.mcp.server"
    restart: unless-stopped
    networks:
      - devops-ai-net

volumes:
  dbdata: {}
  ollama: {}
  chroma_data: {}

networks:
  devops-ai-net: {}
